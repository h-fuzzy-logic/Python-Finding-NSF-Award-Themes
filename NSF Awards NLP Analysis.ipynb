{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Text analysis of 2019 Award Data from National Science Foundation which is avaialble at https://www.nsf.gov/awardsearch/download.jsp.  NSF provides the data as XML files and it has been transformed into a CSV file that is used in this notebook.\n",
    "\n",
    "The goal is to analyze the Award Titles and Award Abstracts to understand the the type of Awards granted in 2019. \n",
    "\n",
    "This notebook is meant to present the final result of the analysis at a high level.  It does not show the intermediate, debugging, and QA-ing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/heather/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/heather/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# To make cell outputs easier to read \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "get_ipython().ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/2015-2019-awards.csv\");\n",
    "df_2019 = df[df.AwardYear == 2019]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thought process\n",
    "Do a few checks to make sure the data seems reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11754, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Filename               object \n",
       "AwardYear              int64  \n",
       "AwardTitle             object \n",
       "InstName               object \n",
       "City                   object \n",
       "Zip                    object \n",
       "Phone                  float64\n",
       "Street                 object \n",
       "Country                object \n",
       "StateName              object \n",
       "StateCode              object \n",
       "AwardAmt               int64  \n",
       "InitialAwardAmt        float64\n",
       "AwardInstrumentType    object \n",
       "Directorate            object \n",
       "Division               object \n",
       "Abstract               object \n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>AwardYear</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>InstName</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Street</th>\n",
       "      <th>Country</th>\n",
       "      <th>StateName</th>\n",
       "      <th>StateCode</th>\n",
       "      <th>AwardAmt</th>\n",
       "      <th>InitialAwardAmt</th>\n",
       "      <th>AwardInstrumentType</th>\n",
       "      <th>Directorate</th>\n",
       "      <th>Division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25353</th>\n",
       "      <td>1900008.xml</td>\n",
       "      <td>2019</td>\n",
       "      <td>Collaborative research: Weighted Estimates with Matrix Weights and Non-Homogeneous Harmonic Analysis</td>\n",
       "      <td>Kent State University</td>\n",
       "      <td>KENT</td>\n",
       "      <td>442420001</td>\n",
       "      <td>3.306722e+09</td>\n",
       "      <td>OFFICE OF THE COMPTROLLER</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>119539</td>\n",
       "      <td>194964.0</td>\n",
       "      <td>Continuing Grant</td>\n",
       "      <td>Direct For Mathematical &amp; Physical Scien</td>\n",
       "      <td>Division Of Mathematical Sciences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename  AwardYear  \\\n",
       "25353  1900008.xml  2019        \n",
       "\n",
       "                                                                                                 AwardTitle  \\\n",
       "25353  Collaborative research: Weighted Estimates with Matrix Weights and Non-Homogeneous Harmonic Analysis   \n",
       "\n",
       "                    InstName  City        Zip         Phone  \\\n",
       "25353  Kent State University  KENT  442420001  3.306722e+09   \n",
       "\n",
       "                          Street        Country StateName StateCode  AwardAmt  \\\n",
       "25353  OFFICE OF THE COMPTROLLER  United States  Ohio      OH        119539     \n",
       "\n",
       "       InitialAwardAmt AwardInstrumentType  \\\n",
       "25353  194964.0         Continuing Grant     \n",
       "\n",
       "                                    Directorate  \\\n",
       "25353  Direct For Mathematical & Physical Scien   \n",
       "\n",
       "                                Division  \n",
       "25353  Division Of Mathematical Sciences  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "25353    Calderon-Zygmund operators are objects that are largely responsible for our understanding of a number of physical phenomena, from heat transfer to turbulence. Recently, these operators have found application in big data analysis. The classical theory was built by Alberto Calderon and Antoni Zygmund in the early 1950s, and was intrinsically designed to work on smooth objects. However, nature often puzzles us with very irregular medium. Thus, the need arose for a very low regularity Calderon-Zygmund theory, which the three PIs have, in fact, constructed. One possible application of such low regularity theory is that by the action of Calderon-Zygmund operators on a set in a space of a very high dimension, we can conclude that the set itself is nicely structured and can be analyzed. This is a typical big data problem. Our other recent observation is that well-studied problems for such an operator can be dualized to provide new information for analysis on the hypercube - another widely used model of big data.<br/><br/><br/>This project will consider the following problems, presented here in their simplest by formulation: 1) Sharp end-point weak weighted estimates for the square function operator in the homogeneous setting; 2) What goes wrong in the non-homogeneous case; 3) Matrix A_2 problems for Calderon--Zygmund operators, the square function operator, their sparse operators analogies and their sharp estimates; 4) How to get from end-point estimates of the square function to geometric inequalities on the hypercube and in Gaussian space; 5) The David-Semmes problem for co-dimension higher than one; 6) Harmonic measure estimates on sets of co-dimension bigger than one; and 7) Estimates from below of singular Riesz transforms by positive geometric quantities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.\n",
       "Name: Abstract, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.shape\n",
    "df_2019.AwardTitle.dtypes\n",
    "df_2019.AwardAmt.dtypes\n",
    "df_2019.Abstract.dtypes\n",
    "df_2019.dtypes\n",
    "df_2019[df_2019.columns[:-1]].head(1)\n",
    "df_2019.Abstract.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thought process \n",
    "* Use def's to make the code easier to understand \n",
    "* Steps for cleaning the Award Title and Abstract\n",
    "  1. Fill nulls with empty string \n",
    "  1. Change all words to lower case \n",
    "  1. Remove common words that do not add meaning \n",
    "  1. Remove puncutation, non-alpha characters  \n",
    "  1. Set AwardTitle and Abstract back to the cleaned text\n",
    "  1. Proceed with finding nGrams and concepts/topics\n",
    "* Decided not to expand contractions, use stemming, use lemmatization   \n",
    "* Probably room to make the cleaning code more efficient but it is running quickly for this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'also', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'project', 're', 'research', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'use', 'used', 'using', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "# Being very intentional about what is being removed.  Decided against regex becuase it seems more likely to\n",
    "# have unintentionally consequences.  Decided to specify exactly what remove\n",
    "\n",
    "stopset=set(stopwords.words(\"english\"))\n",
    "stopset.update(['also', 'research', \"'s\", 'project', 'use', 'using', 'used'])\n",
    "noise = ['(e.g.', '<br/>', '-', '>', '<', '(', ')', '2019', '?', '&', ':', ';', ',', '.']\n",
    "print(sorted(stopset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to handle cleaning the text\n",
    "\n",
    "def RemoveNoise(txt_col):\n",
    "    txt_col = txt_col.fillna(\"\").str.lower()\n",
    "    for n in noise:\n",
    "        txt_col = txt_col.str.replace(n, \" \", regex=False)\n",
    "    return txt_col\n",
    "\n",
    "def GetMeaningfulText(txt):\n",
    "    tokens = word_tokenize(txt)\n",
    "    meaningful_words = [w for w in tokens if w not in stopset]\n",
    "    return ' '.join(meaningful_words)\n",
    "    \n",
    "#does the remove noise need to happen cell by cell? \n",
    "def UpdateColsRemoveNoise(df):\n",
    "    df.Abstract = RemoveNoise(df.Abstract)\n",
    "    df.AwardTitle = RemoveNoise(df.AwardTitle)\n",
    "    df.AwardTitle = df.AwardTitle.map(GetMeaningfulText)\n",
    "    df.Abstract = df.Abstract.map(GetMeaningfulText)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to handle nGram logic\n",
    "\n",
    "def GetAllWordsInCorpus(ngrams_col):\n",
    "    word_list = []\n",
    "    for row in ngrams_col:\n",
    "        for words in row:\n",
    "            word_list.append(words)\n",
    "    return word_list    \n",
    "\n",
    "# Turning the NLTK fdist into a dataframe, to help get the top results and create \n",
    "# the phrases with spaces.  \n",
    "def GetDataFrameFromFDistTopNgrams(fdist):\n",
    "    return pd.DataFrame.from_records(data=fdist.most_common(10000),\n",
    "                                      columns=['NGram', 'Count'])\n",
    "\n",
    "#should this param be called _col? \n",
    "def GetTopPhrases(ngrams_col):\n",
    "    if (ngrams_col.size > 0):\n",
    "        words = GetAllWordsInCorpus(ngrams_col)\n",
    "        ngram_dist = nltk.FreqDist(words)\n",
    "        ngram_df = pd.DataFrame()\n",
    "        ngram_df = GetDataFrameFromFDistTopNgrams(ngram_dist)\n",
    "        return ngram_df['NGram'].agg(' '.join).head(25).to_numpy()\n",
    "    else:\n",
    "        return null\n",
    "\n",
    "def CreateNGramSummaryDf(df_directorate):\n",
    "    df_summary = pd.DataFrame()\n",
    "    \n",
    "    df_directorate['words'] = df_directorate.AwardTitle.apply(lambda row: list(nltk.ngrams (row.split(), 1)))\n",
    "    df_summary['TitleWord'] = GetTopPhrases(df_directorate.words)\n",
    "    \n",
    "    df_directorate['bigrams'] = df_directorate.AwardTitle.apply(lambda row: list(nltk.ngrams (row.split(), 2)))\n",
    "    df_summary['TitleBigram'] = GetTopPhrases(df_directorate.bigrams)\n",
    "\n",
    "    df_directorate['trigrams'] = df_directorate.AwardTitle.apply(lambda row: list(nltk.ngrams (row.split(), 3)))\n",
    "    df_summary['TitleTrigram'] = GetTopPhrases(df_directorate.trigrams)\n",
    "    \n",
    "    df_directorate['abstractWords'] = df_directorate.Abstract.apply(lambda row: list(nltk.ngrams (row.split(), 1)))\n",
    "    df_summary['AbstractWord'] = GetTopPhrases(df_directorate.abstractWords)\n",
    "    \n",
    "    df_directorate['abstractBigrams'] = df_directorate.Abstract.apply(lambda row: list(nltk.ngrams (row.split(), 2)))\n",
    "    df_summary['AbstractBigram'] = GetTopPhrases(df_directorate.abstractBigrams)\n",
    "    \n",
    "    df_directorate['abstractTrigrams'] = df_directorate.Abstract.apply(lambda row: list(nltk.ngrams (row.split(), 3)))\n",
    "    df_summary['AbstractTrigram'] = GetTopPhrases(df_directorate.abstractTrigrams)\n",
    "    \n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of choices for TfidfVectorizer parameters\n",
    "\n",
    "* **use_idf** controls how the frequency per word is calculated, using either the:\n",
    "   1. Raw counts OR \n",
    "   2. Counts when taking into consideration the importance of the word (so that common words like 'the' will be less important) \n",
    "\n",
    "Decision: Since this analysis removes stop words before vectorizing, setting use_idf to True or False yeilds the same concepts. \n",
    "\n",
    "\n",
    "* **ngram_range** controls the number of words in the topics. \n",
    "\n",
    "Decision: Since the nGram exploration in this analysis considered words, bigrams, and trigrams, ngram_range was set to match with (1,3)\n",
    "\n",
    "#### Explanation of choices for TruncatedSVD parameters\n",
    "\n",
    "* According to the documentation, **n_iter**=100 is recommended for LSA\n",
    "* **n_components**=5 seems like a reasonable number of concepts to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetConceptsWithTopics(textAsList):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopset, use_idf=False, ngram_range=(1,3))\n",
    "    X = vectorizer.fit_transform(textAsList)\n",
    "    lsa = TruncatedSVD(n_components=5, n_iter=100)\n",
    "    lsa.fit(X)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    \n",
    "    all_concepts=\"\"\n",
    "    for i, comp in enumerate(lsa.components_):\n",
    "        termsInComp = zip(terms, comp)\n",
    "        sortedTerms = sorted(termsInComp, key=lambda x: x[1], reverse=True)[:10]\n",
    "        conceptWithTopics = (\"Concept %d: \" % i)\n",
    "        conceptWithTopics += ', '.join(str(t[0]) for t in sortedTerms)\n",
    "        all_concepts += conceptWithTopics\n",
    "        all_concepts += \"\\n\\r\"\n",
    "    return all_concepts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which Directorates to investigate.  Can investigate many or one.  \n",
    "# But exclude the ones with incomplete data\n",
    "\n",
    "#directorates = df_2019.Directorate.unique()\n",
    "directorates = ['Direct For Computer & Info Scie & Enginr']\n",
    "\n",
    "to_exclude = ['nan', 'Office Of Information & Resource Mgmt', \\\n",
    "              'Office of Budget, Finance, & Award Management', \\\n",
    "             'National Coordination Office', \\\n",
    "             'Natl Nanotechnology Coordinating Office']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct For Computer & Info Scie & Enginr\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TitleWord</th>\n",
       "      <th>TitleBigram</th>\n",
       "      <th>TitleTrigram</th>\n",
       "      <th>AbstractWord</th>\n",
       "      <th>AbstractBigram</th>\n",
       "      <th>AbstractTrigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>core small</td>\n",
       "      <td>cns core small</td>\n",
       "      <td>data</td>\n",
       "      <td>intellectual merit</td>\n",
       "      <td>award reflects nsf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collaborative</td>\n",
       "      <td>medium collaborative</td>\n",
       "      <td>satc core medium</td>\n",
       "      <td>learning</td>\n",
       "      <td>broader impacts</td>\n",
       "      <td>reflects nsf statutory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>cns core</td>\n",
       "      <td>satc core small</td>\n",
       "      <td>new</td>\n",
       "      <td>support evaluation</td>\n",
       "      <td>nsf statutory mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learning</td>\n",
       "      <td>satc core</td>\n",
       "      <td>core medium collaborative</td>\n",
       "      <td>support</td>\n",
       "      <td>award reflects</td>\n",
       "      <td>statutory mission deemed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>core</td>\n",
       "      <td>shf small</td>\n",
       "      <td>cps medium collaborative</td>\n",
       "      <td>science</td>\n",
       "      <td>reflects nsf</td>\n",
       "      <td>mission deemed worthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medium</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>cyber physical systems</td>\n",
       "      <td>systems</td>\n",
       "      <td>nsf statutory</td>\n",
       "      <td>deemed worthy support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>systems</td>\n",
       "      <td>core medium</td>\n",
       "      <td>cns core medium</td>\n",
       "      <td>nsf</td>\n",
       "      <td>statutory mission</td>\n",
       "      <td>worthy support evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shf</td>\n",
       "      <td>ri small</td>\n",
       "      <td>shf medium collaborative</td>\n",
       "      <td>foundation</td>\n",
       "      <td>mission deemed</td>\n",
       "      <td>support evaluation foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>science</td>\n",
       "      <td>cif small</td>\n",
       "      <td>oac core small</td>\n",
       "      <td>broader</td>\n",
       "      <td>deemed worthy</td>\n",
       "      <td>evaluation foundation intellectual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>satc</td>\n",
       "      <td>chs small</td>\n",
       "      <td>nri int collab</td>\n",
       "      <td>impacts</td>\n",
       "      <td>worthy support</td>\n",
       "      <td>foundation intellectual merit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cns</td>\n",
       "      <td>data science</td>\n",
       "      <td>high performance computing</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>evaluation foundation</td>\n",
       "      <td>intellectual merit broader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computing</td>\n",
       "      <td>iii small</td>\n",
       "      <td>sch int collaborative</td>\n",
       "      <td>award</td>\n",
       "      <td>foundation intellectual</td>\n",
       "      <td>merit broader impacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>based</td>\n",
       "      <td>af small</td>\n",
       "      <td>bd hubs collaborative</td>\n",
       "      <td>students</td>\n",
       "      <td>merit broader</td>\n",
       "      <td>broader impacts review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ri</td>\n",
       "      <td>cps medium</td>\n",
       "      <td>hubs collaborative proposal</td>\n",
       "      <td>mission</td>\n",
       "      <td>impacts review</td>\n",
       "      <td>impacts review criteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cps</td>\n",
       "      <td>collaborative frameworks</td>\n",
       "      <td>big data innovation</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>review criteria</td>\n",
       "      <td>harnessing data revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>machine</td>\n",
       "      <td>data driven</td>\n",
       "      <td>hdr dsc collaborative</td>\n",
       "      <td>merit</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>high performance computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>high</td>\n",
       "      <td>shf medium</td>\n",
       "      <td>ccri ens collaborative</td>\n",
       "      <td>review</td>\n",
       "      <td>data science</td>\n",
       "      <td>national science foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>software</td>\n",
       "      <td>reu site</td>\n",
       "      <td>fw htf rm</td>\n",
       "      <td>criteria</td>\n",
       "      <td>computer science</td>\n",
       "      <td>cyber physical systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>network</td>\n",
       "      <td>fet small</td>\n",
       "      <td>medium collaborative towards</td>\n",
       "      <td>reflects</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>machine learning algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iii</td>\n",
       "      <td>real time</td>\n",
       "      <td>collaborative aim interpretable</td>\n",
       "      <td>deemed</td>\n",
       "      <td>real time</td>\n",
       "      <td>undergraduate graduate students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chs</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>aim interpretable augmented</td>\n",
       "      <td>statutory</td>\n",
       "      <td>real world</td>\n",
       "      <td>natural language processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>design</td>\n",
       "      <td>big data</td>\n",
       "      <td>interpretable augmented intelligence</td>\n",
       "      <td>worthy</td>\n",
       "      <td>high performance</td>\n",
       "      <td>part national science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cif</td>\n",
       "      <td>cyber physical</td>\n",
       "      <td>augmented intelligence multiscale</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>large scale</td>\n",
       "      <td>high school students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>system</td>\n",
       "      <td>cps small</td>\n",
       "      <td>intelligence multiscale material</td>\n",
       "      <td>software</td>\n",
       "      <td>open source</td>\n",
       "      <td>deep neural networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>networks</td>\n",
       "      <td>hdr tripods</td>\n",
       "      <td>multiscale material discovery</td>\n",
       "      <td>models</td>\n",
       "      <td>state art</td>\n",
       "      <td>science foundation harnessing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TitleWord               TitleBigram  \\\n",
       "0   small          core small                 \n",
       "1   collaborative  medium collaborative       \n",
       "2   data           cns core                   \n",
       "3   learning       satc core                  \n",
       "4   core           shf small                  \n",
       "5   medium         machine learning           \n",
       "6   systems        core medium                \n",
       "7   shf            ri small                   \n",
       "8   science        cif small                  \n",
       "9   satc           chs small                  \n",
       "10  cns            data science               \n",
       "11  computing      iii small                  \n",
       "12  based          af small                   \n",
       "13  ri             cps medium                 \n",
       "14  cps            collaborative frameworks   \n",
       "15  machine        data driven                \n",
       "16  high           shf medium                 \n",
       "17  software       reu site                   \n",
       "18  network        fet small                  \n",
       "19  iii            real time                  \n",
       "20  chs            deep learning              \n",
       "21  design         big data                   \n",
       "22  cif            cyber physical             \n",
       "23  system         cps small                  \n",
       "24  networks       hdr tripods                \n",
       "\n",
       "                            TitleTrigram  AbstractWord  \\\n",
       "0   cns core small                        data           \n",
       "1   satc core medium                      learning       \n",
       "2   satc core small                       new            \n",
       "3   core medium collaborative             support        \n",
       "4   cps medium collaborative              science        \n",
       "5   cyber physical systems                systems        \n",
       "6   cns core medium                       nsf            \n",
       "7   shf medium collaborative              foundation     \n",
       "8   oac core small                        broader        \n",
       "9   nri int collab                        impacts        \n",
       "10  high performance computing            evaluation     \n",
       "11  sch int collaborative                 award          \n",
       "12  bd hubs collaborative                 students       \n",
       "13  hubs collaborative proposal           mission        \n",
       "14  big data innovation                   intellectual   \n",
       "15  hdr dsc collaborative                 merit          \n",
       "16  ccri ens collaborative                review         \n",
       "17  fw htf rm                             criteria       \n",
       "18  medium collaborative towards          reflects       \n",
       "19  collaborative aim interpretable       deemed         \n",
       "20  aim interpretable augmented           statutory      \n",
       "21  interpretable augmented intelligence  worthy         \n",
       "22  augmented intelligence multiscale     algorithms     \n",
       "23  intelligence multiscale material      software       \n",
       "24  multiscale material discovery         models         \n",
       "\n",
       "             AbstractBigram                     AbstractTrigram  \n",
       "0   intellectual merit       award reflects nsf                  \n",
       "1   broader impacts          reflects nsf statutory              \n",
       "2   support evaluation       nsf statutory mission               \n",
       "3   award reflects           statutory mission deemed            \n",
       "4   reflects nsf             mission deemed worthy               \n",
       "5   nsf statutory            deemed worthy support               \n",
       "6   statutory mission        worthy support evaluation           \n",
       "7   mission deemed           support evaluation foundation       \n",
       "8   deemed worthy            evaluation foundation intellectual  \n",
       "9   worthy support           foundation intellectual merit       \n",
       "10  evaluation foundation    intellectual merit broader          \n",
       "11  foundation intellectual  merit broader impacts               \n",
       "12  merit broader            broader impacts review              \n",
       "13  impacts review           impacts review criteria             \n",
       "14  review criteria          harnessing data revolution          \n",
       "15  machine learning         high performance computing          \n",
       "16  data science             national science foundation         \n",
       "17  computer science         cyber physical systems              \n",
       "18  deep learning            machine learning algorithms         \n",
       "19  real time                undergraduate graduate students     \n",
       "20  real world               natural language processing         \n",
       "21  high performance         part national science               \n",
       "22  large scale              high school students                \n",
       "23  open source              deep neural networks                \n",
       "24  state art                science foundation harnessing       "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorate Award Amount mean:  $383,801.41\n",
      "Number of Above Average awards: 778\n",
      "Concept 0: data, learning, new, support, science, systems, nsf, foundation, broader, impacts\n",
      "\r",
      "Concept 1: data, science, data science, big, data revolution, national, revolution, harnessing data, harnessing data revolution, big data\n",
      "\r",
      "Concept 2: learning, machine, machine learning, models, algorithms, deep, neural, deep learning, networks, methods\n",
      "\r",
      "Concept 3: science, students, learning, data science, materials, university, computer, computer science, engineering, community\n",
      "\r",
      "Concept 4: systems, materials, new, models, methods, physical, software, science, engineering, manufacturing\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TitleWord</th>\n",
       "      <th>TitleBigram</th>\n",
       "      <th>TitleTrigram</th>\n",
       "      <th>AbstractWord</th>\n",
       "      <th>AbstractBigram</th>\n",
       "      <th>AbstractTrigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collaborative</td>\n",
       "      <td>small collaborative</td>\n",
       "      <td>nsf student travel</td>\n",
       "      <td>data</td>\n",
       "      <td>broader impacts</td>\n",
       "      <td>intellectual merit broader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>medium collaborative</td>\n",
       "      <td>student travel grant</td>\n",
       "      <td>support</td>\n",
       "      <td>intellectual merit</td>\n",
       "      <td>award reflects nsf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>student travel</td>\n",
       "      <td>core small collaborative</td>\n",
       "      <td>new</td>\n",
       "      <td>merit broader</td>\n",
       "      <td>reflects nsf statutory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>career</td>\n",
       "      <td>travel grant</td>\n",
       "      <td>cns core small</td>\n",
       "      <td>students</td>\n",
       "      <td>award reflects</td>\n",
       "      <td>nsf statutory mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learning</td>\n",
       "      <td>nsf student</td>\n",
       "      <td>shf small collaborative</td>\n",
       "      <td>learning</td>\n",
       "      <td>reflects nsf</td>\n",
       "      <td>statutory mission deemed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medium</td>\n",
       "      <td>cns core</td>\n",
       "      <td>core medium collaborative</td>\n",
       "      <td>systems</td>\n",
       "      <td>nsf statutory</td>\n",
       "      <td>mission deemed worthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>student</td>\n",
       "      <td>core small</td>\n",
       "      <td>iii small collaborative</td>\n",
       "      <td>science</td>\n",
       "      <td>statutory mission</td>\n",
       "      <td>deemed worthy support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>systems</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>af small collaborative</td>\n",
       "      <td>nsf</td>\n",
       "      <td>mission deemed</td>\n",
       "      <td>worthy support evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eager</td>\n",
       "      <td>shf small</td>\n",
       "      <td>cns core medium</td>\n",
       "      <td>award</td>\n",
       "      <td>deemed worthy</td>\n",
       "      <td>support evaluation foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>computing</td>\n",
       "      <td>iii small</td>\n",
       "      <td>ri small collaborative</td>\n",
       "      <td>broader</td>\n",
       "      <td>worthy support</td>\n",
       "      <td>evaluation foundation intellectual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>travel</td>\n",
       "      <td>international conference</td>\n",
       "      <td>student travel support</td>\n",
       "      <td>foundation</td>\n",
       "      <td>support evaluation</td>\n",
       "      <td>foundation intellectual merit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>core</td>\n",
       "      <td>af small</td>\n",
       "      <td>eager satc early</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>evaluation foundation</td>\n",
       "      <td>merit broader impacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nsf</td>\n",
       "      <td>core medium</td>\n",
       "      <td>satc early stage</td>\n",
       "      <td>impacts</td>\n",
       "      <td>foundation intellectual</td>\n",
       "      <td>broader impacts review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>conference</td>\n",
       "      <td>ri small</td>\n",
       "      <td>early stage interdisciplinary</td>\n",
       "      <td>mission</td>\n",
       "      <td>impacts review</td>\n",
       "      <td>impacts review criteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grant</td>\n",
       "      <td>satc core</td>\n",
       "      <td>stage interdisciplinary collaboration</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>review criteria</td>\n",
       "      <td>harnessing data revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>science</td>\n",
       "      <td>data science</td>\n",
       "      <td>chs small collaborative</td>\n",
       "      <td>review</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>national science foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cns</td>\n",
       "      <td>chs small</td>\n",
       "      <td>satc core small</td>\n",
       "      <td>criteria</td>\n",
       "      <td>data science</td>\n",
       "      <td>part national science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>workshop</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>chs medium collaborative</td>\n",
       "      <td>merit</td>\n",
       "      <td>computer science</td>\n",
       "      <td>science foundation harnessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>crii</td>\n",
       "      <td>cif small</td>\n",
       "      <td>cif small collaborative</td>\n",
       "      <td>reflects</td>\n",
       "      <td>large scale</td>\n",
       "      <td>foundation harnessing data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shf</td>\n",
       "      <td>computer science</td>\n",
       "      <td>satc core medium</td>\n",
       "      <td>statutory</td>\n",
       "      <td>real world</td>\n",
       "      <td>big idea activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>based</td>\n",
       "      <td>chs medium</td>\n",
       "      <td>travel grant ieee</td>\n",
       "      <td>deemed</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>data revolution hdr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>satc</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>hdr dsc collaborative</td>\n",
       "      <td>worthy</td>\n",
       "      <td>real time</td>\n",
       "      <td>revolution hdr big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>networks</td>\n",
       "      <td>travel support</td>\n",
       "      <td>shf medium collaborative</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>graduate students</td>\n",
       "      <td>hdr big idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>large scale</td>\n",
       "      <td>travel grant acm</td>\n",
       "      <td>design</td>\n",
       "      <td>data revolution</td>\n",
       "      <td>high school students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>machine</td>\n",
       "      <td>cyber physical</td>\n",
       "      <td>cyber physical systems</td>\n",
       "      <td>computing</td>\n",
       "      <td>state art</td>\n",
       "      <td>cyber physical systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TitleWord               TitleBigram  \\\n",
       "0   collaborative  small collaborative        \n",
       "1   small          medium collaborative       \n",
       "2   data           student travel             \n",
       "3   career         travel grant               \n",
       "4   learning       nsf student                \n",
       "5   medium         cns core                   \n",
       "6   student        core small                 \n",
       "7   systems        machine learning           \n",
       "8   eager          shf small                  \n",
       "9   computing      iii small                  \n",
       "10  travel         international conference   \n",
       "11  core           af small                   \n",
       "12  nsf            core medium                \n",
       "13  conference     ri small                   \n",
       "14  grant          satc core                  \n",
       "15  science        data science               \n",
       "16  cns            chs small                  \n",
       "17  workshop       deep learning              \n",
       "18  crii           cif small                  \n",
       "19  shf            computer science           \n",
       "20  based          chs medium                 \n",
       "21  satc           artificial intelligence    \n",
       "22  networks       travel support             \n",
       "23  algorithms     large scale                \n",
       "24  machine        cyber physical             \n",
       "\n",
       "                             TitleTrigram  AbstractWord  \\\n",
       "0   nsf student travel                     data           \n",
       "1   student travel grant                   support        \n",
       "2   core small collaborative               new            \n",
       "3   cns core small                         students       \n",
       "4   shf small collaborative                learning       \n",
       "5   core medium collaborative              systems        \n",
       "6   iii small collaborative                science        \n",
       "7   af small collaborative                 nsf            \n",
       "8   cns core medium                        award          \n",
       "9   ri small collaborative                 broader        \n",
       "10  student travel support                 foundation     \n",
       "11  eager satc early                       evaluation     \n",
       "12  satc early stage                       impacts        \n",
       "13  early stage interdisciplinary          mission        \n",
       "14  stage interdisciplinary collaboration  intellectual   \n",
       "15  chs small collaborative                review         \n",
       "16  satc core small                        criteria       \n",
       "17  chs medium collaborative               merit          \n",
       "18  cif small collaborative                reflects       \n",
       "19  satc core medium                       statutory      \n",
       "20  travel grant ieee                      deemed         \n",
       "21  hdr dsc collaborative                  worthy         \n",
       "22  shf medium collaborative               algorithms     \n",
       "23  travel grant acm                       design         \n",
       "24  cyber physical systems                 computing      \n",
       "\n",
       "             AbstractBigram                     AbstractTrigram  \n",
       "0   broader impacts          intellectual merit broader          \n",
       "1   intellectual merit       award reflects nsf                  \n",
       "2   merit broader            reflects nsf statutory              \n",
       "3   award reflects           nsf statutory mission               \n",
       "4   reflects nsf             statutory mission deemed            \n",
       "5   nsf statutory            mission deemed worthy               \n",
       "6   statutory mission        deemed worthy support               \n",
       "7   mission deemed           worthy support evaluation           \n",
       "8   deemed worthy            support evaluation foundation       \n",
       "9   worthy support           evaluation foundation intellectual  \n",
       "10  support evaluation       foundation intellectual merit       \n",
       "11  evaluation foundation    merit broader impacts               \n",
       "12  foundation intellectual  broader impacts review              \n",
       "13  impacts review           impacts review criteria             \n",
       "14  review criteria          harnessing data revolution          \n",
       "15  machine learning         national science foundation         \n",
       "16  data science             part national science               \n",
       "17  computer science         science foundation harnessing       \n",
       "18  large scale              foundation harnessing data          \n",
       "19  real world               big idea activity                   \n",
       "20  deep learning            data revolution hdr                 \n",
       "21  real time                revolution hdr big                  \n",
       "22  graduate students        hdr big idea                        \n",
       "23  data revolution          high school students                \n",
       "24  state art                cyber physical systems              "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of At or Below Average awards: 1330\n",
      "Concept 0: data, support, students, new, learning, systems, science, award, nsf, broader\n",
      "\r",
      "Concept 1: data, science, learning, data science, machine, machine learning, models, big, algorithms, data revolution\n",
      "\r",
      "Concept 2: data, students, conference, science, data science, researchers, student, travel, support, workshop\n",
      "\r",
      "Concept 3: learning, machine, machine learning, students, science, models, conference, algorithms, student, deep\n",
      "\r",
      "Concept 4: science, materials, computing, software, new, computer, computer science, computational, development, scientific\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "for d in [d for d in directorates if str(d) not in to_exclude]:\n",
    "    df_dir = df_2019[df_2019.Directorate==d].copy(deep=True)\n",
    "    dir_mean = df_dir.AwardAmt.mean()\n",
    "    df_dir['IsAboveMeanAwardAmt'] = (df_dir.AwardAmt > dir_mean)  \n",
    "    \n",
    "    print (d)\n",
    "    print(\" \")\n",
    "    \n",
    "    df_dir = UpdateColsRemoveNoise(df_dir)\n",
    "    \n",
    "    df_above = df_dir[df_dir.IsAboveMeanAwardAmt == True].copy(deep=True)\n",
    "    df_overview_above = CreateNGramSummaryDf(df_above) \n",
    "    df_overview_above\n",
    "    concepts_above = GetConceptsWithTopics(df_above.Abstract.values.tolist())\n",
    "    print (\"Directorate Award Amount mean: \", '${:,.2f}'.format(dir_mean))\n",
    "    print(\"Number of Above Average awards: \" + str(len(df_above)))\n",
    "    print(concepts_above) \n",
    "    \n",
    "    df_below = df_dir[df_dir.IsAboveMeanAwardAmt == False].copy(deep=True)\n",
    "    df_overview_below = CreateNGramSummaryDf(df_below) \n",
    "    df_overview_below\n",
    "    concepts_below = GetConceptsWithTopics(df_below.Abstract.values.tolist())\n",
    "    print(\"Number of At or Below Average awards: \" + str(len(df_below)))\n",
    "    print(concepts_below) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit44835759d09e47bda2a23a1a2a640941"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
